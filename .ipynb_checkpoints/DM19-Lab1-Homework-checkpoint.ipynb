{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:\n",
    "鍾明遠\n",
    "\n",
    "Student ID:\n",
    "108011557\n",
    "\n",
    "GitHub ID:\n",
    "mchung0417"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: do the **take home** exercises in the [DM19-Lab1-Master Repo](https://github.com/EvaArevalo/DM19-Lab1-Master). You may need to copy some cells from the Lab notebook to this notebook. __This part is worth 20% of your grade.__\n",
    "\n",
    "\n",
    "2. Second: follow the same process from the [DM19-Lab1-Master Repo](https://github.com/EvaArevalo/DM19-Lab1-Master) on **the new dataset**. You don't need to explain all details as we did (some **minimal comments** explaining your code are useful though).  __This part is worth 30% of your grade.__\n",
    "    - Download the [the new dataset](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#). The dataset contains a `sentence` and `score` label. Read the specificiations of the dataset for details. \n",
    "    - You are allowed to use and modify the `helper` functions in the folder of the first lab session (notice they may need modification) or create your own.\n",
    "\n",
    "\n",
    "3. Third: please attempt the following tasks on **the new dataset**. __This part is worth 30% of your grade.__\n",
    "    - Generate meaningful **new data visualizations**. Refer to online resources and the Data Mining textbook for inspiration and ideas. \n",
    "    - Generate **TF-IDF features** from the tokens of each text. This will generating a document matrix, however, the weights will be computed differently (using the TF-IDF value of each word per document as opposed to the word frequency). Refer to this Sciki-learn [guide](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) .\n",
    "    - Implement a simple **Naive Bayes classifier** that automatically classifies the records into their categories. Use both the TF-IDF features and word frequency features to build two seperate classifiers. Comment on the differences.  Refer to this [article](https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/).\n",
    "\n",
    "\n",
    "4. Fourth: In the lab, we applied each step really quickly just to illustrate how to work with your dataset. There are somethings that are not ideal or the most efficient/meaningful. Each dataset can be habdled differently as well. What are those inefficent parts you noticed? How can you improve the Data preprocessing for these specific datasets? __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "5. Fifth: It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**. __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/EvaArevalo/DM19-Lab1-Master/blob/master/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb). Make sure to commit and save your changes to your repository __BEFORE the deadline (Oct. 29th 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  > First - take home excercise in DM Lab1 Master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Exercise 2 (take home):\n",
    " \n",
    "Experiment with other querying techniques using pandas dataframes. Refer to their [documentation](https://pandas.pydata.org/pandas-docs/stable/indexing.html) for more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From: Mike_Peredo@mindlink.bc.ca (Mike Peredo)...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>From: dotsonm@dmapub.dma.org (Mark Dotson) Sub...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>From: dstampe@psych.toronto.edu (Dave Stampe) ...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>From: vgwlu@dunsell.calgary.chevron.com (greg ...</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>From: BOCHERC@hartwick.edu Subject: Does God L...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>From: david-s@hsr.no (David A. Sjoen) Subject:...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>From: jaeger@buphy.bu.edu (Gregg Jaeger) Subje...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>From: ab@nova.cc.purdue.edu (Allen B) Subject:...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>From: ken@cs.UAlberta.CA (Huisman Kenneth M) S...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>From: Nanci Ann Miller &lt;nm0w+@andrew.cmu.edu&gt; ...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>From: dkennett@fraser.sfu.ca (Daniel Kennett) ...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>From: weaver@chdasic.sps.mot.com (Dave Weaver)...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>From: brr1@ns1.cc.lehigh.edu (BRANT RICHARD RI...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>From: annick@cortex.physiol.su.oz.au (Annick A...</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>From: sts@mfltd.co.uk (Steve Sherwood (x5543))...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text           category_name\n",
       "15  From: Mike_Peredo@mindlink.bc.ca (Mike Peredo)...           comp.graphics\n",
       "20  From: dotsonm@dmapub.dma.org (Mark Dotson) Sub...  soc.religion.christian\n",
       "25  From: dstampe@psych.toronto.edu (Dave Stampe) ...           comp.graphics\n",
       "30  From: vgwlu@dunsell.calgary.chevron.com (greg ...                 sci.med\n",
       "35  From: BOCHERC@hartwick.edu Subject: Does God L...  soc.religion.christian\n",
       "40  From: david-s@hsr.no (David A. Sjoen) Subject:...  soc.religion.christian\n",
       "45  From: jaeger@buphy.bu.edu (Gregg Jaeger) Subje...             alt.atheism\n",
       "50  From: ab@nova.cc.purdue.edu (Allen B) Subject:...           comp.graphics\n",
       "55  From: ken@cs.UAlberta.CA (Huisman Kenneth M) S...           comp.graphics\n",
       "60  From: Nanci Ann Miller <nm0w+@andrew.cmu.edu> ...             alt.atheism\n",
       "65  From: dkennett@fraser.sfu.ca (Daniel Kennett) ...           comp.graphics\n",
       "70  From: weaver@chdasic.sps.mot.com (Dave Weaver)...  soc.religion.christian\n",
       "75  From: brr1@ns1.cc.lehigh.edu (BRANT RICHARD RI...           comp.graphics\n",
       "80  From: annick@cortex.physiol.su.oz.au (Annick A...                 sci.med\n",
       "85  From: sts@mfltd.co.uk (Steve Sherwood (x5543))...           comp.graphics"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "import helpers.data_mining_helpers as dmh\n",
    "\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, \\\n",
    "                                  shuffle=True, random_state=42)\n",
    "\n",
    "X = pd.DataFrame.from_records(dmh.format_rows(twenty_train), columns= ['text'])\n",
    "X['category'] = twenty_train.target\n",
    "X['category_name'] = X.category.apply(lambda t: dmh.format_labels(t, twenty_train))\n",
    "X.iloc[15:2000:5,0:4:2][0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5 (take home):\n",
    "\n",
    "There is an old saying that goes, \"The devil is in the details.\" When we are working with extremely large data, it's difficult to check records one by one (as we have been doing so far). And also, we don't even know what kind of missing values we are facing. Thus, \"debugging\" skills get sharper as we spend more time solving bugs. Let's focus on a different method to check for missing values and the kinds of missing values you may encounter. It's not easy to check for missing values as you will find out in a minute.\n",
    "\n",
    "Please check the data and the process below, describe what you observe and why it happened.   \n",
    "$Hint$ :  why `.isnull()` didn't work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>missing_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id missing_example\n",
       "0  A             NaN\n",
       "1  B             NaN\n",
       "2  C             NaN\n",
       "3  D            None\n",
       "4  E            None\n",
       "5  F                "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "NA_dict = [{ 'id': 'A', 'missing_example': np.nan },\n",
    "           { 'id': 'B'                    },\n",
    "           { 'id': 'C', 'missing_example': 'NaN'  },\n",
    "           { 'id': 'D', 'missing_example': 'None' },\n",
    "           { 'id': 'E', 'missing_example':  None  },\n",
    "           { 'id': 'F', 'missing_example': ''     }]\n",
    "\n",
    "NA_df = pd.DataFrame(NA_dict, columns = ['id','missing_example'])\n",
    "NA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4     True\n",
       "5    False\n",
       "Name: missing_example, dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NA_df['missing_example'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "1    True\n",
       "2    True\n",
       "3    True\n",
       "4    True\n",
       "5    True\n",
       "Name: missing_example, dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NA_df.replace(to_replace=['NaN','None',''], value=np.nan,inplace=True)\n",
    "NA_df['missing_example'].isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because isnull() function can only find judge np.nan kind missing value\n",
    "\n",
    "in order to use it properly,I replace the different kind of missing value to np.nan\n",
    "\n",
    "that makes isnull() function works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Exercise 6 (take home):\n",
    "        \n",
    "Notice any changes to the `X` dataframe? What are they? Report every change you noticed as compared to the previous state of `X`. Feel free to query and look more closely at the dataframe for these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X.sample(n=1000) #random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: sd345@city.ac.uk (Michael Collier) Subje...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: s0612596@let.rug.nl (M.M. Zwart) Subject...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>From: vbv@lor.eeap.cwru.edu (Virgilio (Dean) B...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: anasaz!karl@anasazi.com (Karl Dussik) Su...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Subject: So what is Maddi? From: madhaus@netco...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From: Mike_Peredo@mindlink.bc.ca (Mike Peredo)...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>From: texx@ossi.com (Robert \"Texx\" Woodworth) ...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Organization: Penn State University From: &lt;JSN...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>From: tom_milligan@rainbow.mentorg.com Subject...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>From: gmiller@worldbank.org (Gene C. Miller) S...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>From: ruthless@panix.com (Ruth Ditucci) Subjec...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>From: rind@enterprise.bih.harvard.edu (David R...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>From: spp@zabriskie.berkeley.edu (Steve Pope) ...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>From: vgwlu@dunsell.calgary.chevron.com (greg ...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>From:  (Phil Bowermaster) Subject: C. S. Lewis...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>From: doyle+@pitt.edu (Howard R Doyle) Subject...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>From: jsledd@ssdc.sas.upenn.edu (James Sledd) ...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>From: geb@cs.pitt.edu (Gordon Banks) Subject: ...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>From: BOCHERC@hartwick.edu Subject: Does God L...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>From: g9134255@wampyr.cc.uow.edu.au (Coronado ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>From: jaeger@buphy.bu.edu (Gregg Jaeger) Subje...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>From: ab@nova.cc.purdue.edu (Allen B) Subject:...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>From: noring@netcom.com (Jon Noring) Subject: ...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Subject: Re: A visit from the Jehovah's Witnes...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>From: joachim@kih.no (joachim lous) Subject: R...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>From: Nanci Ann Miller &lt;nm0w+@andrew.cmu.edu&gt; ...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>From: gifford@oasys.dt.navy.mil (Barbara Giffo...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>From: weston@ucssun1.sdsu.edu (weston t) Subje...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>From: kmr4@po.CWRU.edu (Keith M. Ryan) Subject...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>From: freemant@dcs.glasgow.ac.uk (Toby Freeman...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>Subject: Re: Can't Breathe -- Update From: RGI...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>From: REXLEX@fnal.fnal.gov Subject: Re: Athies...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>From: max@hilbert.cyprs.rain.com (Max Webb) Su...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>From: tmc@spartan.ac.BrockU.CA (Tim Ciceran) S...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>From: rind@enterprise.bih.harvard.edu (David R...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>From: kellyb@ccsua.ctstateu.edu Subject: Re: B...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>From: romdas@uclink.berkeley.edu (Ella I Baff)...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>From: kai_h@postoffice.utas.edu.au (Kai Howell...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>From: dyer@spdcc.com (Steve Dyer) Subject: Re:...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>From: billj@b11.b11.ingr.com (Bill Jones) Subj...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>From: jono@mac-ak-24.rtsg.mot.com (Jon Ogden) ...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>From: jsledd@ssdc.sas.upenn.edu (James Sledd) ...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>From: edimg@willard.atl.ga.us (Ed pimentel) Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>From: davidk@welch.jhu.edu (David \"Go-Go\" Kita...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>Subject: Re: Speculations From: dgraham@bmers3...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>From: naren@tekig1.PEN.TEK.COM (Naren Bala) Su...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>From: mcovingt@aisun3.ai.uga.edu (Michael Covi...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>From: jsledd@ssdc.sas.upenn.edu (James Sledd) ...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>From: havardn@edb.tih.no (Haavard Nesse,o92a) ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>From: nahess@mir.gatech.edu (Nicholas A. Hess)...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>From: jcj@tellabs.com (jcj) Subject: Re: proof...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>From: balick@nynexst.com (Daphne Balick) Subje...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>From: daniels@math.ufl.edu (TV's Big Dealer) S...</td>\n",
       "      <td>3</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>From: \"danny hawrysio\" &lt;danny.hawrysio@canrem....</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>From: Mark-Tarbell@suite.com Subject: Amniocen...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>From: roos@Operoni.Helsinki.FI (Christophe Roo...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>From: Dan Wallach &lt;dwallach@cs.berkeley.edu&gt; S...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  category  \\\n",
       "0     From: sd345@city.ac.uk (Michael Collier) Subje...         1   \n",
       "3     From: s0612596@let.rug.nl (M.M. Zwart) Subject...         3   \n",
       "5     From: vbv@lor.eeap.cwru.edu (Virgilio (Dean) B...         3   \n",
       "10    From: anasaz!karl@anasazi.com (Karl Dussik) Su...         3   \n",
       "12    From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...         0   \n",
       "13    Subject: So what is Maddi? From: madhaus@netco...         0   \n",
       "15    From: Mike_Peredo@mindlink.bc.ca (Mike Peredo)...         1   \n",
       "16    From: texx@ossi.com (Robert \"Texx\" Woodworth) ...         2   \n",
       "17    Organization: Penn State University From: <JSN...         0   \n",
       "18    From: tom_milligan@rainbow.mentorg.com Subject...         3   \n",
       "21    From: gmiller@worldbank.org (Gene C. Miller) S...         0   \n",
       "27    From: ruthless@panix.com (Ruth Ditucci) Subjec...         3   \n",
       "28    From: rind@enterprise.bih.harvard.edu (David R...         2   \n",
       "29    From: spp@zabriskie.berkeley.edu (Steve Pope) ...         2   \n",
       "30    From: vgwlu@dunsell.calgary.chevron.com (greg ...         2   \n",
       "31    From:  (Phil Bowermaster) Subject: C. S. Lewis...         3   \n",
       "32    From: doyle+@pitt.edu (Howard R Doyle) Subject...         2   \n",
       "33    From: jsledd@ssdc.sas.upenn.edu (James Sledd) ...         3   \n",
       "34    From: geb@cs.pitt.edu (Gordon Banks) Subject: ...         2   \n",
       "35    From: BOCHERC@hartwick.edu Subject: Does God L...         3   \n",
       "36    From: keith@cco.caltech.edu (Keith Allan Schne...         0   \n",
       "39    From: g9134255@wampyr.cc.uow.edu.au (Coronado ...         1   \n",
       "45    From: jaeger@buphy.bu.edu (Gregg Jaeger) Subje...         0   \n",
       "50    From: ab@nova.cc.purdue.edu (Allen B) Subject:...         1   \n",
       "51    From: noring@netcom.com (Jon Noring) Subject: ...         2   \n",
       "52    Subject: Re: A visit from the Jehovah's Witnes...         0   \n",
       "59    From: joachim@kih.no (joachim lous) Subject: R...         1   \n",
       "60    From: Nanci Ann Miller <nm0w+@andrew.cmu.edu> ...         0   \n",
       "61    From: gifford@oasys.dt.navy.mil (Barbara Giffo...         3   \n",
       "64    From: weston@ucssun1.sdsu.edu (weston t) Subje...         1   \n",
       "...                                                 ...       ...   \n",
       "2184  From: kmr4@po.CWRU.edu (Keith M. Ryan) Subject...         0   \n",
       "2185  From: freemant@dcs.glasgow.ac.uk (Toby Freeman...         1   \n",
       "2186  Subject: Re: Can't Breathe -- Update From: RGI...         2   \n",
       "2190  From: REXLEX@fnal.fnal.gov Subject: Re: Athies...         3   \n",
       "2191  From: max@hilbert.cyprs.rain.com (Max Webb) Su...         3   \n",
       "2192  From: tmc@spartan.ac.BrockU.CA (Tim Ciceran) S...         1   \n",
       "2194  From: rind@enterprise.bih.harvard.edu (David R...         2   \n",
       "2196  From: kellyb@ccsua.ctstateu.edu Subject: Re: B...         0   \n",
       "2199  From: romdas@uclink.berkeley.edu (Ella I Baff)...         2   \n",
       "2201  From: kai_h@postoffice.utas.edu.au (Kai Howell...         1   \n",
       "2202  From: dyer@spdcc.com (Steve Dyer) Subject: Re:...         2   \n",
       "2203  From: keith@cco.caltech.edu (Keith Allan Schne...         0   \n",
       "2204  From: billj@b11.b11.ingr.com (Bill Jones) Subj...         1   \n",
       "2205  From: jono@mac-ak-24.rtsg.mot.com (Jon Ogden) ...         3   \n",
       "2206  From: jsledd@ssdc.sas.upenn.edu (James Sledd) ...         3   \n",
       "2210  From: edimg@willard.atl.ga.us (Ed pimentel) Su...         1   \n",
       "2211  From: davidk@welch.jhu.edu (David \"Go-Go\" Kita...         0   \n",
       "2216  Subject: Re: Speculations From: dgraham@bmers3...         0   \n",
       "2217  From: naren@tekig1.PEN.TEK.COM (Naren Bala) Su...         0   \n",
       "2221  From: mcovingt@aisun3.ai.uga.edu (Michael Covi...         3   \n",
       "2223  From: jsledd@ssdc.sas.upenn.edu (James Sledd) ...         3   \n",
       "2224  From: havardn@edb.tih.no (Haavard Nesse,o92a) ...         1   \n",
       "2226  From: nahess@mir.gatech.edu (Nicholas A. Hess)...         1   \n",
       "2229  From: jcj@tellabs.com (jcj) Subject: Re: proof...         3   \n",
       "2240  From: balick@nynexst.com (Daphne Balick) Subje...         2   \n",
       "2247  From: daniels@math.ufl.edu (TV's Big Dealer) S...         3   \n",
       "2248  From: \"danny hawrysio\" <danny.hawrysio@canrem....         1   \n",
       "2251  From: Mark-Tarbell@suite.com Subject: Amniocen...         2   \n",
       "2252  From: roos@Operoni.Helsinki.FI (Christophe Roo...         2   \n",
       "2255  From: Dan Wallach <dwallach@cs.berkeley.edu> S...         2   \n",
       "\n",
       "               category_name  \n",
       "0              comp.graphics  \n",
       "3     soc.religion.christian  \n",
       "5     soc.religion.christian  \n",
       "10    soc.religion.christian  \n",
       "12               alt.atheism  \n",
       "13               alt.atheism  \n",
       "15             comp.graphics  \n",
       "16                   sci.med  \n",
       "17               alt.atheism  \n",
       "18    soc.religion.christian  \n",
       "21               alt.atheism  \n",
       "27    soc.religion.christian  \n",
       "28                   sci.med  \n",
       "29                   sci.med  \n",
       "30                   sci.med  \n",
       "31    soc.religion.christian  \n",
       "32                   sci.med  \n",
       "33    soc.religion.christian  \n",
       "34                   sci.med  \n",
       "35    soc.religion.christian  \n",
       "36               alt.atheism  \n",
       "39             comp.graphics  \n",
       "45               alt.atheism  \n",
       "50             comp.graphics  \n",
       "51                   sci.med  \n",
       "52               alt.atheism  \n",
       "59             comp.graphics  \n",
       "60               alt.atheism  \n",
       "61    soc.religion.christian  \n",
       "64             comp.graphics  \n",
       "...                      ...  \n",
       "2184             alt.atheism  \n",
       "2185           comp.graphics  \n",
       "2186                 sci.med  \n",
       "2190  soc.religion.christian  \n",
       "2191  soc.religion.christian  \n",
       "2192           comp.graphics  \n",
       "2194                 sci.med  \n",
       "2196             alt.atheism  \n",
       "2199                 sci.med  \n",
       "2201           comp.graphics  \n",
       "2202                 sci.med  \n",
       "2203             alt.atheism  \n",
       "2204           comp.graphics  \n",
       "2205  soc.religion.christian  \n",
       "2206  soc.religion.christian  \n",
       "2210           comp.graphics  \n",
       "2211             alt.atheism  \n",
       "2216             alt.atheism  \n",
       "2217             alt.atheism  \n",
       "2221  soc.religion.christian  \n",
       "2223  soc.religion.christian  \n",
       "2224           comp.graphics  \n",
       "2226           comp.graphics  \n",
       "2229  soc.religion.christian  \n",
       "2240                 sci.med  \n",
       "2247  soc.religion.christian  \n",
       "2248           comp.graphics  \n",
       "2251                 sci.med  \n",
       "2252                 sci.med  \n",
       "2255                 sci.med  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found that X_sample is random select form X , everytime I try to sample it,\n",
    "\n",
    "X_sample is different , I thought that if I want to get the proper subset from X,\n",
    "\n",
    "I should add some conditions like 'sample from each category proportional "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 8 (take home):\n",
    "\n",
    "We can also do a side-by-side comparison of the distribution between the two datasets, but maybe you can try that as an excerise. Below we show you an snapshot of the type of chart we are looking for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt txt](https://i.imgur.com/9eO431H.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Category distribution')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "class_a= X.category_name.value_counts()\n",
    "class_b = X_sample.category_name.value_counts()\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.bar(categories, class_a, label = 'class_a', align = \"edge\", width = -0.25)\n",
    "plt.bar(categories, class_b, label = 'class_b', align = \"edge\", width = 0.25)\n",
    "plt.legend(labels=['X','X_sample'])\n",
    "plt.ylabel('counts')\n",
    "plt.title('Category distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Exercise 10 (take home):\n",
    " \n",
    "We said that the `1` at the beginning of the fifth record represents the `00` term. Notice that there is another 1 in the same record. Can you provide code that can verify what word this 1 represents from the vocabulary. Try to do this as efficient as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 11 (take home):\n",
    "\n",
    "From the chart above, we can see how sparse the term-document matrix is; i.e., there is only one terms with frequency of `1` in the subselection of the matrix. By the way, you may have noticed that we only selected 20 articles and 20 terms to plot the histrogram. As an excersise you can try to modify the code above to plot the entire term-document matrix or just a sample of it. How would you do this efficiently? Remember there is a lot of words in the vocab. Report below what methods you would use to get a nice and useful visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Exercise 12 (take home):\n",
    " \n",
    "Please try to reduce the dimension to 3, and plot the result use 3-D plot. Use at least 3 different angle (camera position) to check your result and describe what you found.\n",
    "\n",
    "$Hint$: you can refer to Axes3D in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 13 (take home):\n",
    " \n",
    "If you want a nicer interactive visualization here, I would encourage you try to install and use plotly to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 14 (take home):\n",
    "\n",
    "The chart above contains all the vocabulary, and it's computationally intensive to both compute and visualize. Can you efficiently reduce the number of terms you want to visualize as an exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 15 (take home):\n",
    "\n",
    "Additionally, you can attempt to sort the terms on the `x-axis` by frequency instead of in alphabetical order. This way the visualization is more meaninfgul and you will be able to observe the so called [long tail](https://en.wikipedia.org/wiki/Long_tail) (get familiar with this term since it will appear a lot in data mining and other statistics courses). see picture below\n",
    "\n",
    "![alt txt](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Long_tail.svg/1000px-Long_tail.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 16 (take home):\n",
    "\n",
    "Try to generate the binarization using the `category_name` column instead. Does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  > Second - The new dataset,follow the steps in DM Lab1 msater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = pd.read_csv('imdb_labelled.txt',sep='\\t',header = None)\n",
    "imdb.columns = ['sentence','score']\n",
    "amazon = pd.read_csv('amazon_cells_labelled.txt',sep='\\t',header = None)\n",
    "amazon.columns = ['sentence','score']\n",
    "yelp = pd.read_csv('yelp_labelled.txt',sep='\\t',header = None)\n",
    "yelp.columns = ['sentence','score']\n",
    "Y = pd.concat([imdb,amazon,yelp],axis = 0)\n",
    "Y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    (The amoung of missing records is: , 0)\n",
       "score       (The amoung of missing records is: , 0)\n",
       "dtype: object"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.isnull().apply(lambda x: dmh.check_missing_values(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Definitely worth checking out.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>10/10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Definitely worth checking out.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>Not recommended.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Not recommended.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>10/10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>Works great!.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>If you like a loud buzzing to override all you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>Don't buy this product.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>Great phone!.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>Works great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>Great phone!.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>Great Phone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>This is a great deal.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>Excellent product for the price.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>Works great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>Does not fit.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>Works great!.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>Don't buy this product.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>Great phone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>If you like a loud buzzing to override all you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>Does not fit.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>This is a great deal.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>Great Phone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>Excellent product for the price.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>Great phone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>I love this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>I won't be back.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>The food was terrible.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>I would not recommend this place.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>I love this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>The food was terrible.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>I won't be back.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>I would not recommend this place.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  score\n",
       "90                     Definitely worth checking out.        1\n",
       "125                                             10/10        1\n",
       "363                    Definitely worth checking out.        1\n",
       "572                                  Not recommended.        0\n",
       "585                                  Not recommended.        0\n",
       "788                                             10/10        1\n",
       "1018                                      Works great!.      1\n",
       "1179  If you like a loud buzzing to override all you...      0\n",
       "1180                            Don't buy this product.      0\n",
       "1187                                      Great phone!.      1\n",
       "1262                                       Works great.      1\n",
       "1285                                      Great phone!.      1\n",
       "1290                                       Great Phone.      1\n",
       "1392                              This is a great deal.      1\n",
       "1402                   Excellent product for the price.      1\n",
       "1407                                       Works great.      1\n",
       "1446                                      Does not fit.      0\n",
       "1524                                      Works great!.      1\n",
       "1543                            Don't buy this product.      0\n",
       "1647                                       Great phone.      1\n",
       "1744  If you like a loud buzzing to override all you...      0\n",
       "1748                                      Does not fit.      0\n",
       "1778                              This is a great deal.      1\n",
       "1792                                       Great Phone.      1\n",
       "1892                   Excellent product for the price.      1\n",
       "1896                                       Great phone.      1\n",
       "2334                                 I love this place.      1\n",
       "2380                                   I won't be back.      0\n",
       "2383                             The food was terrible.      0\n",
       "2505                  I would not recommend this place.      0\n",
       "2814                                 I love this place.      1\n",
       "2816                             The food was terrible.      0\n",
       "2843                                   I won't be back.      0\n",
       "2846                  I would not recommend this place.      0"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[Y.duplicated('sentence',keep = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cascade imdb,yelp,amazon three data set to Y \n",
    "\n",
    "check it and there is no null value in 'sentance' and 'score' columns\n",
    "\n",
    "find out there are 34 duplicate 'sentence' and they have same 'score'\n",
    "\n",
    "so I keep the duplicate 'sentance' that shows first time and delete the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a, very, very, very, slow, moving, aimless, m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[not, sure, who, was, more, lost, the, flat, c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[attempting, artiness, with, black, white, and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[very, little, music, or, anything, to, speak,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[the, best, scene, in, the, movie, was, when, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score\n",
       "0  [a, very, very, very, slow, moving, aimless, m...      0\n",
       "1  [not, sure, who, was, more, lost, the, flat, c...      0\n",
       "2  [attempting, artiness, with, black, white, and...      0\n",
       "3  [very, little, music, or, anything, to, speak,...      0\n",
       "4  [the, best, scene, in, the, movie, was, when, ...      1"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "word_tokenize = RegexpTokenizer('\\w+')\n",
    "Y['sentence'] = Y['sentence'].str.lower()\n",
    "Y['sentence']= Y['sentence'].apply(lambda x:word_tokenize.tokenize(x))\n",
    "Y['sentence'].iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lower the letters then use RegexpTokenizer to tokenize the sentence and remove the punctuation mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [slow, moving, aimless, movie, distressed, dri...\n",
       "1    [sure, lost, flat, characters, audience, nearl...\n",
       "2    [attempting, artiness, black, white, clever, c...\n",
       "3                     [little, music, anything, speak]\n",
       "4    [best, scene, movie, gerardo, trying, find, so...\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "Y['sentence']=Y['sentence'].apply(lambda x: [item for item in x if item not in stop])\n",
    "Y['sentence'].iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slow move aimless movi distress drift young man</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sure lost flat charact audienc nearli half walk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attempt arti black white clever camera angl mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>littl music anyth speak</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best scene movi gerardo tri find song keep run...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score\n",
       "0    slow move aimless movi distress drift young man      0\n",
       "1    sure lost flat charact audienc nearli half walk      0\n",
       "2  attempt arti black white clever camera angl mo...      0\n",
       "3                            littl music anyth speak      0\n",
       "4  best scene movi gerardo tri find song keep run...      1"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming=PorterStemmer()\n",
    "Y['sentence']=Y['sentence'].apply(lambda x:[stemming.stem(word) for word in x])\n",
    "Y['sentence']=Y['sentence'].apply(lambda x:' '.join(x))\n",
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stemming the words,then return list to str\n",
    "\n",
    "After the steps above, I get the clean dataset for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  > Third - The new dataset,TF IDF and Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2983, 3942)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "count_vect = CountVectorizer()\n",
    "Y_counts = count_vect.fit_transform(Y.sentence)\n",
    "Y_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = count_vect.get_feature_names()\n",
    "Y_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(Y_counts)\n",
    "weight = tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
